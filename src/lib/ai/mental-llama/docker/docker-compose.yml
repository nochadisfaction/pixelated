version: '3.8'

services:
  # API Gateway for load balancing
  nginx:
    image: nginx:alpine
    ports:
      - '8080:80'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - mental-llama-api
    restart: unless-stopped
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--quiet',
          '--tries=1',
          '--spider',
          'http://localhost:80/health',
        ]
      interval: 10s
      timeout: 5s
      retries: 3

  # MentalLLaMA API Service
  mental-llama-api:
    build:
      context: ../../../../
      dockerfile: src/lib/ai/mental-llama/docker/Dockerfile
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G
    environment:
      - NODE_ENV=production
      - EMOTION_LLAMA_API_URL=${EMOTION_LLAMA_API_URL}
      - EMOTION_LLAMA_API_KEY=${EMOTION_LLAMA_API_KEY}
      - FHE_KEY_PATH=/app/certs/fhe.key
      - FHE_CERT_PATH=/app/certs/fhe.cert

      # MentalLLaMA 7B model configuration
      - USE_MENTAL_LLAMA_7B_MODEL=${USE_MENTAL_LLAMA_7B_MODEL:-false}
      - MENTAL_LLAMA_7B_API_URL=${MENTAL_LLAMA_7B_API_URL}
      - MENTAL_LLAMA_7B_API_KEY=${MENTAL_LLAMA_7B_API_KEY}
      - MENTAL_LLAMA_7B_MODEL_NAME=${MENTAL_LLAMA_7B_MODEL_NAME:-MentalLLaMA-chat-7B}

      # MentalLLaMA 13B model configuration
      - USE_MENTAL_LLAMA_13B_MODEL=${USE_MENTAL_LLAMA_13B_MODEL:-false}
      - MENTAL_LLAMA_13B_API_URL=${MENTAL_LLAMA_13B_API_URL}
      - MENTAL_LLAMA_13B_API_KEY=${MENTAL_LLAMA_13B_API_KEY}
      - MENTAL_LLAMA_13B_MODEL_NAME=${MENTAL_LLAMA_13B_MODEL_NAME:-MentalLLaMA-chat-13B}

      # Redis configuration
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RATE_LIMIT_ENABLED=true
      - CACHE_ENABLED=true

      # Monitoring
      - PROMETHEUS_METRICS_ENABLED=true
    volumes:
      - ./certs:/app/certs:ro
    restart: unless-stopped
    depends_on:
      - redis
    networks:
      - mental-llama-network
    healthcheck:
      test: ['CMD', '/app/healthcheck.sh']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # Redis for caching API responses and rate limiting
  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
    restart: unless-stopped
    networks:
      - mental-llama-network
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 5s
      timeout: 5s
      retries: 5

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - '9090:9090'
    restart: unless-stopped
    networks:
      - mental-llama-network
    depends_on:
      - mental-llama-api

  # Grafana for monitoring dashboards
  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - '3001:3000'
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped
    networks:
      - mental-llama-network
    depends_on:
      - prometheus

volumes:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  mental-llama-network:
    driver: bridge
